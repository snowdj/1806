{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 4 solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (5 points)\n",
    "\n",
    "Can a set of linearly independent vectors contain the $\\vec{0}$ vector?  Under what circumstances, if any?\n",
    "\n",
    "## Solution\n",
    "\n",
    "A sequence of vectors $\\vec{v_1}, \\vec{v_2}, ..., \\vec{v_n}$ is linearly independent when\n",
    "\\begin{align}\n",
    "x_1\\vec{v_1} + x_2\\vec{v_2} + ... + x_n\\vec{v_n} = \\vec{0} \\iff x_1=x_2=...=x_n = 0.\n",
    "\\end{align}\n",
    "Suppose one of these vectors is the zero vector, say $\\vec{v_1}=\\vec{0}$. Then $x_1$ can be any real number, while the other coefficients are zero. But then we have found a non trivial linear combination that gives the zero vector. So a set of vectors containing the zero vector can never be linearly independent. \n",
    "\n",
    "Note that even the set $\\{\\vec{0}\\}$ consisting of the *single* vector $\\vec{0}$ is *not* linearly independent, because $x_1\\vec{0} = 0$ for any $x_1$.  Correspondingly, we say that the vector space $\\{\\vec{0}\\}$ is **zero-dimensional**, because there are *no* linearly independent vectors in its basis, and summing the (empty set of) basis vectors is the [empty sum](https://en.wikipedia.org/wiki/Empty_sum), giving $\\{\\vec{0}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (12 points)\n",
    "\n",
    "Give a **basis** and state the **dimensionality** for the following vector spaces and subspaces (for multiplication by real scalars and the ordinary ± operations):\n",
    "\n",
    "1. Functions $p(x)$ that are polynomials of degree ≤ 3 (cubic or less).\n",
    "\n",
    "2. 3-component vectors $\\vec{x} \\in \\mathbb{R}^3$ whose components average to zero.\n",
    "\n",
    "3. $3\\times 3$ matrices $A$ that are *anti-symmetric*: $A = -A^T$.\n",
    "\n",
    "## Solution\n",
    "\n",
    "Note that there are infinitely many possible choices of basis for any vector space that is not 0-dimensional.  Below, we give a simple choice of basis, but other choices are acceptable as well.\n",
    "\n",
    "1. A general polynomial of degree $\\leq 3$ has the form $p(x) = ax^3 + bx^2 +cx + d$, where $a,b,c,d\\in\\mathbb{R}$ are scalars. A possible basis for the set of such polynomials is the set of functions $\\{x^3,x^2,x,1\\}$, where $1$ represents the constant function $f(x)=1$. This set spans the set of polynomials of degree $\\leq 3$ since all such polynomials can be written as linear combinations of these functions. It is also linearly independent. There are four elements in this basis, and so this vector space has **dimension four**.\n",
    "\n",
    "2. Vectors $\\vec{x} \\in \\mathbb{R}^3$ can be written as $\\vec{x} = (x_1,x_2,x_3)$. If the components average to $0$, then this imposes the constraint that $x_1+x_2+x_3 = 0$. This means that we only have freedom to pick two of the components, say $x_1$ and $x_2$, and then the constraint will impose the value of $x_3$, meaning that a basis for this set will contain two vectors. A possible basis for this set of 3-component vectors is \n",
    "\\begin{align}\n",
    "\\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}, \\;\\; \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "These are linearly independent (There is no way to write the first vector as a multiple of the second). There are two elements in this basis and so the dimension of this vector space is **two**.   Another way of thinking about this problem is that we are looking for the **null space** of the matrix $\\begin{pmatrix} 1 & 1 & 1 \\end{pmatrix}$.  Since this is already in rref form (rank 1), we can read off the two special solutions, which form another possible basis:\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\;\\; \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "Again, the vector space is 2 dimensional, because the matrix has rank 1 with 3 columns.\n",
    "\n",
    "3. The most general anti-symmetric matrix is of the form\n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} 0 & a & b \\\\ -a & 0 & c \\\\ -b & -c & 0\\end{pmatrix}.\n",
    "\\end{align}\n",
    "We require three different scalars to describe this matrix. A possible basis is the following set of matrices:\n",
    "\\begin{align}\n",
    "\\bigg\\{\\begin{pmatrix} 0 & 1 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 0 & 0\\end{pmatrix}, \n",
    "\\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 0 & 0 \\\\ -1 & 0 & 0\\end{pmatrix},\n",
    "\\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & -1 & 0\\end{pmatrix}\\bigg\\}\n",
    "\\end{align}\n",
    "There are three elements in the basis, so the vector space has dimension three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 points)\n",
    "\n",
    "Come up with a matrix $A$ and a vector $b \\ne 0$ such that the solutions of $Ax=b$ form a line in $\\mathbb{R}^3$, and all of the entries of $A$ are nonzero.  Find the complete solution (i.e., all solutions) $x$.\n",
    "\n",
    "## Solution\n",
    "\n",
    "We want to find solution to $Ax= b$ where the solutions form a line in $\\mathbb{R}^3$.  This means that (i) the matrix $A$ must have **3 columns**, and (ii) the **rank must be 2** (so that the null space is 1d).\n",
    "\n",
    "The simplest possibility would be any $2 \\times 3$ matrix with full row rank.  For example\n",
    "$$\n",
    "A = \\begin{pmatrix} 1 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}, \n",
    "$$\n",
    "which clearly has full rank because it is in rref form.  The 1d null space is spanned by the special solution (-2,1,0).   Since this matrix has full row rank, any right-hand side will be solvable, but to make things easier on us let's just pick $b=(1,0)$, the first column of $A$, so that a particular solution is $(1,0,0)$.  The complete solution is then:\n",
    "$$\n",
    "x = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\alpha \\begin{pmatrix} -2 \\\\ 1 \\\\ 0 \\end{pmatrix}\n",
    "$$\n",
    "for any scalar α.\n",
    "\n",
    "As another example, let's look for a $3 \\times 3$ matrix $A$ of rank 2 (the matrix actually can have any number of rows greater than two). To do this we can pick any linearly independent vectors for the first two columns (ensuring that none of the entries are $0$!), and then just ensure that the third column is a linear combination of the first two. For example:\n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 4 & 7 \\\\ 5 & 6 & 11 \\end{pmatrix}, \n",
    "\\end{align}\n",
    "where the third column is the sum of the first and the third column. The null space is then spanned by the vector\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "To ensure $Ax = b$ has a solution, we just need to pick a $b$ in the column space, for example\n",
    "\\begin{align}\n",
    "b = \\begin{pmatrix} 2 \\\\ 6 \\\\ 10 \\end{pmatrix},\n",
    "\\end{align}\n",
    "which is the sum of the first two columns, minus the second column. $Ax=b$ then has a particular solution\n",
    "\\begin{align}\n",
    "x_p = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix}. \n",
    "\\end{align}\n",
    "The complete solution is then\n",
    "\\begin{align}\n",
    "x = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} + c_1 \\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1 +c_1\\\\ -1+c_1 \\\\ 1-c_! \\end{pmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (12 points)\n",
    "\n",
    "The following matrix is from **problem 5 of pset 3**:\n",
    "$$\n",
    "A = \\begin{pmatrix} 0 & 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 4 & 6 \\\\ 0 & 0 & 0 & 1 & 2 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**(a)** Give a basis for $C(A)$ and the dimension of this subspace.\n",
    "\n",
    "**(b)** If $b = \\begin{pmatrix} 3 \\\\ 6 \\\\ \\beta \\end{pmatrix}$, for what values of the scalar $\\beta$ will $Ax=b$ have a solution?\n",
    "\n",
    "**(c)** For the $\\beta$ from (b), find the **complete** solution to $Ax=b$.\n",
    "\n",
    "## Solution\n",
    "\n",
    "**(a)** In last week's pset we found that the reduced row echelon form of $A$ was\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} 0 & 1 & 2 & 0 & -2 \\\\ 0 & 0 & 0 & 1 & 2 \\\\ 0 & 0 & 0 & 0 & 0 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "The second and fourth columns are the pivot columns, so the second second and fourth columns of $A$ will form a basis for the column space of $A$, i.e. \n",
    "\\begin{align}\n",
    "\\bigg\\{\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\;\\;\n",
    "\\begin{pmatrix} 3 \\\\ 4 \\\\ 1 \\end{pmatrix}\\bigg\\}\n",
    "\\end{align}\n",
    "is a basis for $C(A)$. It has dimension two.\n",
    "\n",
    "**(b)** If $Ax=b$ has a solution, then $b$ must be in the column space of $A$.  There are several ways of checking this.\n",
    "\n",
    "One way is to perform the same elimination steps on $b=(b_1,b_2,b_3)$ that we did on $A$ and check that the zero rows match.  In pset 3, we subtracted the first row from the second and then the second row from the third row.  Doing the same thing to $b$ gives a third row of $\\beta - 3$, which means that we must have $\\beta=3$ for a solution to exist.\n",
    "\n",
    "Another way is to look for constants $a_1, a_2$ such that\n",
    "\\begin{align}\n",
    "a_1\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} + a_2\\begin{pmatrix} 3 \\\\ 4 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 6 \\\\ \\beta \\end{pmatrix}.\n",
    "\\end{align}\n",
    "Equivalently\n",
    "\\begin{align}\n",
    "a_1+3a_2 &= 3\\\\\n",
    "a_1+4a_2 &= 6\\\\\n",
    "a_2&=\\beta\n",
    "\\end{align}\n",
    "Simultaneously solving the first two equations tells us that $a_1=-6, a_2=3$, and so the final equation tells us that $\\beta=3$. \n",
    "\n",
    "A third way would be to find a basis for $N(A^T)$ and check that $b$ is orthogonal to that.\n",
    "\n",
    "**(c)** In part (b), we found that a particular solution of $Ax = b$ is\n",
    "\\begin{align}\n",
    "x_p = \\begin{pmatrix} 0 \\\\ -6 \\\\ 0 \\\\3 \\\\0 \\end{pmatrix}.\n",
    "\\end{align}\n",
    "We found a basis for the null space in the previous pset. So the **complete** solution to $Ax=b$ is\n",
    "\\begin{align}\n",
    "x &= \\begin{pmatrix} 0 \\\\ -6 \\\\ 0 \\\\3 \\\\ 0 \\end{pmatrix} + c_1 \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\0 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 \\\\ -2 \\\\ 1 \\\\ 0 \\\\0 \\end{pmatrix} + c_3 \\begin{pmatrix}0 \\\\ 2 \\\\ 0 \\\\ -2 \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
