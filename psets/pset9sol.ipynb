{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 9 solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (15 points)\n",
    "\n",
    "**(a)** If $Q$ is an orthogonal matrix ($Q^T = Q^{-1}$), explain why it follows from the rules for determinants that $\\det Q$ must be ........ or ........?\n",
    "\n",
    "**(b)** If $P$ is a $3\\times 3$ projection matrix onto a 2d subspace, then its determinant must be ........?\n",
    "\n",
    "**(c)** The following code generates 20 random 5×5 \"anti-symmetric\" (or \"skew-symmetric\") matrices, and prints their determinants. This is a square matrix $A$ with $A^T=−A$. Explain what you observe using the properties of determinants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)** If $Q$ is an orthogonal, square matrix then we know that $Q^T = Q^{-1}$. By the rules of determinants, we know that $\\det Q^T = \\det Q$ and that $\\det Q^{-1} = \\frac{1}{\\det Q} $. We can then equate these two expressions, to deduce that $\\det Q = \\frac{1}{\\det Q} \\implies \\left(\\det Q \\right)^2 = 1$, which means that $\\det Q = \\pm 1$.\n",
    "\n",
    "**(b)** If $P$ is a $3\\times 3$ projection matrix onto a 2d subspace, then $P$ has rank 2. This means that one of the pivots of $P$ will be zero, and so $\\det P = 0$. \n",
    "\n",
    "**(c)** If $A$ is an $m\\times m$ matrix, then $\\det (-A) = (-1)^m\\det A$. If $A$ is skew symmetric, then $A^T = -A \\implies \\det A^T = \\det (-A) \\implies \\det A = (-1)^m \\det A$. If $m$ is odd, then this necessarily means $\\det A = 0$, which is what we find if we set $m=5$ (or any odd number) in the code below. However, if $m$ is even, then generally $\\det A \\neq 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "m = 5  # you can try changing this too if you want\n",
    "\n",
    "for i = 1:20\n",
    "    A = randn(m,m) # a random m×m matrix\n",
    "    A = A - A' # make it skew-symmetric by subtracting its transpose\n",
    "\n",
    "    println(round(det(A), 13)) # print determinant, rounded to 13 digits\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (10 points)\n",
    "\n",
    "The $2\\times 2$ matrix $A = \\begin{pmatrix} 1 & 4 \\\\ 2 & 3 \\end{pmatrix}$ has eigenvalues $\\lambda_1 = 5$ and $\\lambda_2 = -1$, with corresponding eigenvectors $x_1 = (1,1)$ and $x_2 = (-2,1)$.\n",
    "\n",
    "Find the eigenvalues and eigenvectors of $B = 2A + 3I$.\n",
    "\n",
    "(Before you jump into solving quadratic equations, think about what happens if you multiply $B$ by $x_1$ or $x_2$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Firstly, note that every vector is an eigenvector of the identity matrix with eigenvalue 1. This follows from the fact that $Ix = x$ for all $x$. \n",
    "\n",
    "Now consider $Bx_1$:\n",
    "\\begin{align}\n",
    "Bx_1 &= (2A + 3I) x_1 \\\\\n",
    "&= 2Ax_1 +3Ix_1\\\\\n",
    "&= 2\\lambda_1 x_1 + 3x_1\\\\\n",
    "&= (2\\lambda_1 + 3)x_1\n",
    "\\end{align}\n",
    "So $x_1$ is an eigenvector of $B$ with eigenvalue $2\\lambda_1 + 3 = 13$. The same argument shows that $x_2$ is also an eigenvector of $B$ with eigenvalue $2\\lambda_2 + 3 = 1$. \n",
    "\n",
    "(More generally, using the same procedure we can see that $\\alpha A + \\beta I$ has the *same* eigenvectors as $A$ but each eigenvalue $\\lambda$ is replaced by $\\alpha \\lambda + \\beta$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 points)\n",
    "\n",
    "(Based on Strang, section 6.2, problem 5.)\n",
    "\n",
    "**(a)** If the eigenvectors of $A$ are the columns of $I$ then A is a ........ matrix.\n",
    "\n",
    "**(b)** If the eigenvector matrix $X$ is upper triangular, then why must $A$ also be upper triangular?  (Note: the inverse of an upper-triangular matrix is upper triangular.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)** If the eigenvectors of $A$ are the columns of $I$ then A is a **diagonal** matrix. This follows from the diagonalization formula $A = X\\Lambda X^{-1} = I\\Lambda I^{-1} = \\Lambda$, so $A$ is a diagonal matrix whose entries are necessarily the eigenvalues.\n",
    "\n",
    "**(b)** If the eigenvector matrix $X$ is upper triangular, then so too is its inverse $X^{-1}$. We can then use the diagonalization formula to write $A=X\\Lambda X^{-1}$. However, the product of two upper triangular matrices will remain upper triangular, and since $\\Lambda$ is diagonal (and thus upper triangular), the product $X\\Lambda X^{-1}$ will be upper triangular. Therefore $A$ must be **upper triangular.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (10 points)\n",
    "\n",
    "**(a)** Show that the trace of $A^T A$ must always be $\\ge 0$ by deriving a simple formula for $\\mbox{trace}(A^T A)$ in terms of the matrix entries $a_{ij}$ (i-th row, j-th column) of $A$.  This is called the *Frobenius norm* $$\\Vert A \\Vert_F = \\sqrt{\\mbox{trace}(A^T A)}$$ of the matrix.\n",
    "\n",
    "Check this in Julia for a simple matrix.\n",
    "\n",
    "**(b)** Using the SVD $A = U\\Sigma V^T$, derive a simple relationship between the Frobenius norm $\\Vert A \\Vert_F$ and the singular values $\\sigma_1, \\ldots, \\sigma_r$ of $A$.  (The identity $\\mbox{trace}(BC) = \\mbox{trace}(CB)$ from class will be helpful.)\n",
    "\n",
    "Check this in Julia by computing the singular values of $A$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)** Suppose $A$ is an $m\\times n$ matrix. The trace of $A^TA$ is the sum of the $n$ diagonal entries $(A^TA)_{ii}$. Each of these diagonal entries is given by the sum $(A^TA)_{ii} = \\sum_{j=1}^m a_{ji}^2$. So\n",
    "\\begin{align}\n",
    "\\boxed{\\mbox{trace}(A^T A) = \\sum_{i=1}^n\\sum_{j=1}^m a_{ji}^2},\n",
    "\\end{align}\n",
    "which is necessarily $\\ge 0$ since every term in this sum is squared. \n",
    "\n",
    "Equivalently, the trace is the sum of the diagonal entries, but the diagonal entries of $A^T A$ are the **length² of each column of A** (the dot product of each column with itself).  So the trace is the sum of the length² values, which is the **sum of the squares of all the entries** of A.\n",
    "\n",
    "We can check this in Julia for a simple matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1 2\n",
    "     3 4]\n",
    "trace(A'A) # trace of AᵀA should match your simple formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1,1]^2+A[2,1]^2+A[1,2]^2+A[2,2]^2 # 1²+2²+3²+4² = 1+4+9+16 = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** We can use the SVD to derive a simple relationship between the Frobenius norm $\\Vert A \\Vert_F$ and the singular values by considering $\\mbox{trace}(A^TA)$:\n",
    "\\begin{align}\n",
    "\\mbox{trace}(A^TA) &= \\mbox{trace}\\left[(U\\Sigma V^T)^T(U\\Sigma V^T)\\right]\\\\\n",
    "&= \\mbox{trace}\\left[V\\Sigma^T U^T U\\Sigma V^T\\right]\\\\\n",
    "&= \\mbox{trace}\\left[V\\Sigma \\Sigma V^T\\right]\\\\\n",
    "&= \\mbox{trace}\\left[\\Sigma V^T V\\Sigma \\right]\\\\\n",
    "&= \\mbox{trace}\\left[\\Sigma^2\\right]\\\\\n",
    "&= \\sum_{i=1}^r \\sigma_i^2\n",
    "\\end{align}\n",
    "(In the third line, we used $U^TU=I$ and $\\Sigma^T = \\Sigma$, in the fourth line we used $\\mbox{trace}[AB]=\\mbox{trace}[BA]$, and in the fifth line we used $V^T V = I$.) And so\n",
    "\\begin{align}\n",
    "\\boxed{\\Vert A \\Vert_F = \\sqrt{\\sum_{i=1}^r \\sigma_i^2}}\n",
    "\\end{align}\n",
    "\n",
    "We can then check that the sum of the squares of the singular values of $A$ matches the trace of $A^TA$ that we calculated in part **(a)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ = svdvals(A)\n",
    "σ[1]^2+σ[2]^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(σ)^2 # this is the sum of the squares of the σ[i] values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (7×4=28 points)\n",
    "\n",
    "(Based on Strang, section 6.2, problem 9.)\n",
    "\n",
    "Suppose we form a sequence of numbers $g_0,g_1,g_2,g_3$ by the rule\n",
    "\n",
    "$$\n",
    "g_{k+2} = (1-w) g_{k+1} + w g_k\n",
    "$$\n",
    "\n",
    "for some scalar $w$.  If $0 < w < 1$, then $g_{k+2}$ could be thought of as a **weighted average** of the previous two values in the sequence.  For example, for $w = 0.5$ (equal weights) this produces the sequence\n",
    "$$\n",
    "g_0,g_1,g_2,g_3,\\ldots = 0, 1, \\frac{1}{2}, \\frac{3}{4}, \\frac{5}{8}, \\frac{11}{16}, \\frac{21}{32}, \\frac{43}{64}, \\frac{85}{128}, \\frac{171}{256}, \\frac{341}{512}, \\frac{683}{1024}, \\frac{1365}{2048}, \\frac{2731}{4096}, \\frac{5461}{8192}, \\frac{10923}{16384}, \\frac{21845}{32768}, \\ldots\n",
    "$$\n",
    "\n",
    "**(a)** If we define $x_k = \\begin{pmatrix} g_{k+1} \\\\ g_k \\end{pmatrix}$, then write the rule for the sequence in matrix form: $x_{k+1} = A x_k$.  What is $A$?\n",
    "\n",
    "**(b)** Find the eigenvalues and eigenvectors of A (your answers should be a function of $w$).  Check your answers with the `λ, X = eig(A)` function in Julia for $w=0.1$.\n",
    "\n",
    "**(c)** What happens to the eigenvalues and eigenvectors as $w$ gets closer and closer to $-1$?  Is there a still a basis of eigenvectors and a diagonalization of $A$ for $w=-1$?\n",
    "\n",
    "**(d)** The eigenvalues immediately tell which of these three possibilities occurs for $0 < w < 1$: the sequence *diverges*, *decays*, or *goes to a nonzero constant* as $n\\to\\infty$?    Does this behavior depend on the starting vector $x_0$?\n",
    "\n",
    "**(e)** Find the limit as $n\\to\\infty$ of $A^n$ (for $0 < w < 1$) from the diagonalization of $A$.  (Your answer should be a function of $w$.  Google the formula for the inverse of a $2\\times 2$ matrix if you need it.)\n",
    "\n",
    "**(f)** For $w=0.5$, if $g_0 = 0$ and $g_1 = 1$, i.e. $x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, then show that the sequence approaches 2/3.\n",
    "\n",
    "**(g)** With $w=0.5$, $g_0 = 0$, and $g_1 = 1$ as in the previous part, how fast does $g_n - 2/3$ go to zero?  In particular, you should find that $\\frac{g_{n+1} - 2/3}{g_n - 2/3}$ decays proportional to $\\alpha^n$ for some $\\alpha$.   Check your answer by the using the following Julia code, which numerically computes the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "\n",
    "**(a)** If $x_k = \\begin{pmatrix} g_{k+1} \\\\ g_k \\end{pmatrix}$, then we can use the recurrence relation \n",
    "$$\n",
    "g_{k+2} = (1-w) g_{k+1} + w g_k\n",
    "$$\n",
    "to write\n",
    "$$\n",
    "x_{k+1} = \\begin{pmatrix} g_{k+2} \\\\ g_{k+1} \\end{pmatrix} = \\begin{pmatrix} (1-w) & w \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} g_{k+1} \\\\ g_k \\end{pmatrix} = A x_k.\n",
    "$$\n",
    "\n",
    "**(b)** We can find the eignvalues of our matrix $A$ by solving the characteristic equation $\\det (A-\\lambda I) = 0$:\n",
    "\\begin{align}\n",
    "-\\lambda(1-w-\\lambda) - w = 0 \\implies \\lambda^2 + (w-1)\\lambda - w =0.\n",
    "\\end{align}\n",
    " Solving this quadratic yields:\n",
    " \\begin{align}\n",
    " \\lambda &= \\frac{1-w \\pm \\sqrt {(w-1)^2 + 4w}}{2}\\\\\n",
    "&= \\frac{1-w \\pm \\sqrt {(w+1)^2 }}{2} \\\\\n",
    "&= 1, -w.\n",
    "\\end{align}\n",
    "\n",
    "To find the eigenvector corresponding to $\\lambda_1 = 1$, we solve $(A-I)u_1 = 0$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} -w & w \\\\ 1 & -1 \\end{pmatrix} u_1 = 0 \\;\\; \\implies \\;\\; u_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "To find the eigenvector corresponding to $\\lambda_2 = -w$, we solve $(A+wI)u_2 = 0$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} 1 & w \\\\ 1 & w \\end{pmatrix} u_2 = 0 \\;\\; \\implies \\;\\; u_2 = \\begin{pmatrix} w \\\\ -1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "For $w=0.1$ we should have eigenvalues $1,-0.1$ with corresponding eigenvectors parallel to $u_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $u_2 = \\begin{pmatrix} 0.1 \\\\ -1 \\end{pmatrix}$. We can check this in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "  1.0\n",
       " -0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 0.1;\n",
    "A = [1-w w\n",
    "     1   0];\n",
    "λ, X = eig(A)\n",
    "λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.707107  -0.0995037\n",
       " 0.707107   0.995037 "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues are the same, but the eigenvectors (the columns of $X$) look different. This is because Julia outputs *normalized* eigenvectors. If we divide our $u_1$ and $u_2$ by $\\sqrt{2}$ and $\\sqrt{1^2+0.1^2}$ respectively, then we will get the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.707107\n",
       " 0.707107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -0.0995037\n",
       "  0.995037 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([-0.1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** For $w = -1$, then the eigenvalues will coincide, and $u_2$ will become $\\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$, which is parallel to $u_1$. For this particular value of $w$, the matrix $A$ only has one eigenvalue with one linearly independent eigenvector. This means that there is no basis of eigenvectors and that $A$ will not be diagonalizable ($A$ is \"[defective](https://en.wikipedia.org/wiki/Defective_matrix)\").\n",
    "\n",
    "**(d)** If $x_n = Ax_{n-1}$, then $x_n = A^n x_0$. We can write $x_0$ as a linear combination of the eigenvectors: $x_0 = \\alpha_1 u_1 + \\alpha_2 u_2$. \n",
    "\n",
    "Then $x_n = A^n x_0 = \\alpha_1 u_1 + \\alpha_2 (-w)^n u_2$. Since $0<w<1$, $w^n \\to 0$ as $n \\to \\infty$, and so $x_n \\to \\alpha_1 u_1$, i.e. $g_n$ tends to a nonzero constant as $n\\to \\infty$. However, if $\\alpha_1 = 0$ (if $x_0$ is parallel to $u_2$), then $g_n \\to 0$. \n",
    "\n",
    "**(e)** From the diagonalization formula, we have $A=X\\Lambda X^{-1}$. This means that $A^n = (X\\Lambda X^{-1})^n = (X\\Lambda X^{-1})...(X\\Lambda X^{-1}) = X\\Lambda^n X^{-1}$. We can use the formula for the inverse of a $2\\times 2$ matrix to obtain $X^{-1}$:\n",
    "\\begin{align}\n",
    "X = \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix} \\implies X^{-1} = \\frac{1}{w+1}\\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "So:\n",
    "\\begin{align}\n",
    "A^n &= \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}  \\begin{pmatrix} 1 & 0 \\\\ 0 & (-w)^n \\end{pmatrix} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}\\\\\n",
    "&= \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}\\begin{pmatrix} 1 & w \\\\ (-w)^n & -(-w)^n \\end{pmatrix}\\\\\n",
    "&=  \\frac{1}{w+1} \\begin{pmatrix} 1+w(-w)^n & w-w(-w)^n \\\\ 1-(-w)^n & w+(-w)^n \\end{pmatrix}\n",
    "\\end{align}\n",
    "But $w^n \\to 0$ as $n\\to \\infty$, and so \n",
    "\\begin{align}\n",
    "\\boxed{A^n \\to \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & w \\end{pmatrix}}\n",
    "\\end{align}\n",
    "\n",
    "Alternatively, we could have taken the $n \\to \\infty$ limit *before* multiplying the matrices together to get the same result more easily:\n",
    "\\begin{align}\n",
    "A^\\infty &= \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}  \\underbrace{\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}}_{\\Lambda^\\infty} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix} \\\\\n",
    "&= \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & -1 \\end{pmatrix}  \\begin{pmatrix} 1 & w \\\\ 0 & 0 \\end{pmatrix} = \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & w \\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Notice that $A^\\infty$ is a **rank-1 matrix**: every column is a multiple of $u_1$.  That's because, no matter what vector $x$ you start with, $A^\\infty x$ is a multiple of $u_1$ (the $u_2$ component decays to zero).\n",
    "\n",
    "Let's double-check our $A^n$ formula in Julia for $w = 0.1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.9091  0.0909\n",
       " 0.909   0.091 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.9091  0.0909\n",
       " 0.909   0.091 "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A⁴ = [ 1+w*(-w)^4  w-w*(-w)^4 \n",
    "       1-(-w)^4    w+(-w)^4   ] / (w+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, they match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.0          1.38778e-17\n",
       " 1.11022e-16  2.77556e-17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A^4 - A⁴  # zero to roundoff error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check our limiting formula by plugging in a big exponent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.0  0.1\n",
       " 1.0  0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A^1000 * (w+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** To find the limit of $g_n$ as $n\\to\\infty$ with $g_0 = 0$ and $g_1 = 1$, we find the limit of $x_n = A^n\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ as $n\\to \\infty$:\n",
    "\\begin{align}\n",
    "x_n = A^n \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} &\\to \\frac{1}{w+1} \\begin{pmatrix} 1 & w \\\\ 1 & w \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\\\\n",
    "&= \\frac{1}{w+1} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "Substituting $w=0.5$, we find that $x_n \\to \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, and so $g_n\\to 2/3$ as $n\\to\\infty$. \n",
    "\n",
    "**(g)** We have that:\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} g_{n+1} \\\\ g_n \\end{pmatrix} - \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} & = A^n\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\\\\n",
    "&= \\frac{1}{w+1} \\begin{pmatrix} w(-w)^n & -w(-w)^n \\\\ -(-w)^n & (-w)^n \\end{pmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\\\\n",
    "&= \\frac{1}{w+1} \\begin{pmatrix} w(-w)^n  \\\\ -(-w)^n \\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "We can then deduce that $\\frac{g_{n+1} - 2/3}{g_n - 2/3} = -w = -0.5$.\n",
    "\n",
    "More simply the difference $g_n - 2/3$ is due entirely to the $u_2$ component, which decays as $\\lambda_2^n = (-w)^n$, so the difference must decrease by a factor of $-w$ when we add 1 to $n$.\n",
    "\n",
    "We can then check this ratio in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       " 0.0     \n",
       " 1.0     \n",
       " 0.5     \n",
       " 0.75    \n",
       " 0.625   \n",
       " 0.6875  \n",
       " 0.65625 \n",
       " 0.671875\n",
       " 0.664063\n",
       " 0.667969\n",
       " 0.666016\n",
       " 0.666992\n",
       " 0.666504\n",
       " 0.666748\n",
       " 0.666626\n",
       " 0.666687\n",
       " 0.666656\n",
       " 0.666672\n",
       " 0.666664\n",
       " 0.666668\n",
       " 0.666666\n",
       " 0.666667\n",
       " 0.666667\n",
       " 0.666667\n",
       " 0.666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gsequence(n, w=0.5)\n",
    "    g = [0.0, 1.0]\n",
    "    for i = 3:n\n",
    "        push!(g, (1-w)*g[end] + w *g[end-1])\n",
    "    end\n",
    "    return g\n",
    "end\n",
    "gsequence(25)  # compute gₙ for n=0,1,…,24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Array{Float64,1}:\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = gsequence(25) .- 2/3  # compute gₙ - 2/3\n",
    "[a[n+1] / a[n] for n = 1:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, the ratio $\\frac{g_{n+1} - 2/3}{g_n - 2/3}$ is $-0.5$ (up to roundoff errors)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
