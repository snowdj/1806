{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 problem set 5\n",
    "\n",
    "Due Wednesday, October 10, at 10:55am via Stellar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (12 points)\n",
    "\n",
    "In pset 4, problem 4, you considered the matrix\n",
    "$$\n",
    "A = \\begin{pmatrix} 0 & 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 4 & 6 \\\\ 0 & 0 & 0 & 1 & 2 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**(a)** Find a basis for the *row space* $C(A^T)$.\n",
    "\n",
    "**(b)** Find a basis for the left nullspace $N(A^T)$. Use the fact that $N(A^T) = C(A)^\\perp$ to obtain a condition for $Ax=c$ to be solvable for a vector $c = \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\end{pmatrix}$.\n",
    "\n",
    "**(c)** In pset 4, you considered the vector $b = \\begin{pmatrix} 3 \\\\ 6 \\\\ \\beta \\end{pmatrix}$ and found that $Ax=b$ only had a solution if $\\beta = 3$.  Check that this condition also follows from your answer in (b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (10 points)\n",
    "\n",
    "The set of $2\\times 2$ real matrices form a vector space $\\mathbb{R}^{2\\times2}$.  One possible basis for this vector space is the following set of 4 matrices:\n",
    "$$\n",
    "M_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\;\n",
    "M_2 = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}, \\;\n",
    "M_3 = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\;\n",
    "M_4 = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}.\n",
    "$$\n",
    "That is, we can write any $A \\in \\mathbb{R}^{2\\times2}$ as $A = a_1 M_1 + a_2 M_2 + a_3 M_3 + a_4 M_4$ for $a = \\begin{pmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\end{pmatrix}$: representing **matrices** $A$ by **vectors** $a \\in \\mathbb{R}^4$!\n",
    "\n",
    "Given any $2\\times 2$ matrices\n",
    "$$\n",
    "B = \\begin{pmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{pmatrix}, \\;\n",
    "C = \\begin{pmatrix} c_{11} & c_{12} \\\\ c_{21} & c_{22} \\end{pmatrix},\n",
    "$$\n",
    "we can define a **linear transformation** $T(A) = BAC$ that takes a matrix $A \\in \\mathbb{R}^{2\\times2}$ and gives you another matrix in $\\mathbb{R}^{2\\times2}$.\n",
    "\n",
    "**(a)** Write this $T(A)$ using the basis $\\{ M_1, M_2, M_3, M_4 \\}$ as a *single matrix* $D$ multipying the vector $a$ corresponding to $A$.   Start by expressing your $D$ as the *product of two matrices* (one representing multipling on the left by $B$ and the other representing multiplying on the right by $C$), and *then* multiply them to give a formula for $D$.\n",
    "\n",
    "**(b)** In Julia, you can get $a$ from $A$ by `a = vec(A)`.  For the example matrices given below, fill in `D` and check your answer from (a): check that `vec(B*A*C) = D*vec(A)`.\n",
    "\n",
    "**Extra credit (5 points):** Look up [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product) online, and show that $D$ can be written in terms of a Kronecker product involving $B$ and $C$.  Check your answer in Julia using the `kron(X,Y)` function (which computes the Kronecker product $X \\otimes Y$) to see that it matches your $D$ from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [1 2\n",
    "     3 4]\n",
    "C = [2 -1\n",
    "     1  3]\n",
    "T(A) = B * A * C  # our linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [7  14\n",
    "     23 11]  # example matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vec(A)   # the corresponding vector in our basis M₁,M₂,M₃,M₄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [.....?.....]  # fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that these match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec(T(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D*a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (15 points)\n",
    "\n",
    "In this problem you will solve a nonlinear system of equations by the multidimensional Newton algorithm.\n",
    "\n",
    "In particular, consider the system of equations $f(x) = 0$ where $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\in \\mathbb{R}^2$ and\n",
    "$$\n",
    "f(x) = \\begin{pmatrix} \\frac{1}{2}\\sin(x_1 x_2) - \\frac{x_2}{4\\pi} - \\frac{x_1}{2} \\\\ \\left(1 - \\frac{1}{4\\pi}\\right) \\left(e^{2x_1 - 1} - 1\\right) + \\frac{x_2}{\\pi} - 2x_1 \\end{pmatrix}\n",
    "$$\n",
    "(This is a well known test problem from a 1966 PhD thesis by K. M. Brown at Purdue.)\n",
    "\n",
    "**(a)** Write a function `f(x) = [something, something]` in Julia that implements this $f$.   Note that $x_1$ and $x_2$ are `x[1]` and `x[2]` in Julia, and there is a function `exp(x)` for $e^x$ as well as `expm1(x)` for $e^x - 1$.  The constant $\\pi$ is defined in Julia as `pi` or `π`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = [ first component ,\n",
    "         second component ]  # fill this in (keep the comma!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Run `Pkg.add(\"ForwardDiff\")` to install the [ForwardDiff package](https://github.com/JuliaDiff/ForwardDiff.jl), and use it to define a Jacobian function `J(x) = ForwardDiff.jacobian(f, x)` function that computes the Jacobian matrix.   Compute **one entry** of the Jacobian matrix by **hand** and check that it matches `J(x)` for some point `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"ForwardDiff\") # install this package if you don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ForwardDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J(x) = ForwardDiff.jacobian(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J([1,2])  # check the Jacobian matrix for some point, e.g. x = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Run the following code to plot your $\\Vert f(x) \\Vert$ in order to get a picture of where some of its roots (white spots) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "X = linspace(-2,2,250)\n",
    "Y = linspace(-5,5,200)\n",
    "pcolor(X', Y, [-log(0.01 + norm(f([x,y]))) for y in Y, x in X], cmap=\"gray\")\n",
    "xlabel(L\"x_1\")\n",
    "ylabel(L\"x_2\")\n",
    "title(L\"-\\log [ 0.01 + \\Vert f(x) \\Vert]\")\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Pick one of the roots that you see on the plot and set `x` to be roughly the location of the root.  Run a few Newton iterations `x = x - J(x) \\ f(x)`.   How many iterations do you need for the length $\\Vert f(x) \\Vert$, computed via `norm(f(x))` in Julia, to become less than $10^{-10}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [???, ???]  # initial guess\n",
    "\n",
    "# run 100 Newton iterations and print ‖f(x)‖\n",
    "for i = 1:100\n",
    "    x = x - J(x) \\ f(x)\n",
    "    println(\"iteration $i residual ‖f(x)‖ = \", norm(f(x)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Newton's method converges very rapidly *if* you start out close to the root.  However, if you start out farther away, it can jump around unpredictably, and *which* root it converges (in problems like this with multiple roots) to can be quite surprising.\n",
    "\n",
    "Run the following code, which runs 20 Newton iterations for many different starting points in the $(x_1, x_2)$ plane and plots the final $x_1$, to see this behavior.  (It might be interesting to change the `X` and `Y` limits to zoom in on different portions of the plot.)\n",
    "\n",
    "You should see an instance of a [Newton fractal](https://en.wikipedia.org/wiki/Newton_fractal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function newtoniters(x, N=20) \n",
    "    for i = 1:N\n",
    "        y = f(x)\n",
    "        norm(y) < 1e-10 && break # converged\n",
    "        x = x - J(x) \\ y\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "X = linspace(-2,2,250)\n",
    "Y = linspace(-5,5,200)\n",
    "pcolor(X', Y, [newtoniters([x,y])[1] for y in Y, x in X], vmin=-2, vmax=2)\n",
    "xlabel(L\"x_1\")\n",
    "ylabel(L\"x_2\")\n",
    "colorbar()\n",
    "title(L\"$x_1$ after 20 Newton iterations at different starting $x$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (10 points)\n",
    "\n",
    "(Based on Strang, section 4.1, problem 9.)\n",
    "\n",
    "The following is an important property of the very important matrix $A^T A$ (for real matrices) that will come up several times in 18.06:\n",
    "\n",
    "* If $A^TAx=0$ then $Ax=0$.  Reason: If $A^TAx=0$, then $Ax$ is in the nullspace of $A^T$ and also in the ?????? of $A$, and those spaces are ???????.  Conclusion: $N(A^T A) = N(A)$.\n",
    "\n",
    "* Alternative proof: $A^TAx=0$, then $x^T A^T Ax = 0 = (Ax)^T (Ax)$.  Why does this imply that $Ax=0$?   (Hint: if $y^Ty = 0$, can we have $y\\ne 0$?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (10 points)\n",
    "\n",
    "(From Strang, section 3.5, problem 4)\n",
    "\n",
    "Construct matrices with each of the following properties, or explain why it is impossible:\n",
    "\n",
    "* Column space contains $\\begin{pmatrix} 1\\\\1\\\\0 \\end{pmatrix}$, $\\begin{pmatrix} 0\\\\0\\\\1 \\end{pmatrix}$, and row space contains $\\begin{pmatrix} 1\\\\2 \\end{pmatrix}$, $\\begin{pmatrix} 2 \\\\5 \\end{pmatrix}$\n",
    "\n",
    "* Column space has basis $\\begin{pmatrix} 1\\\\1\\\\3 \\end{pmatrix}$, nullspace has basis $\\begin{pmatrix} 3\\\\1\\\\1 \\end{pmatrix}$\n",
    "\n",
    "* Dimension of nullspace = 1 + dimension of left nullspace\n",
    "\n",
    "* Nullspace contains $\\begin{pmatrix} 1\\\\3 \\end{pmatrix}$, column space contains $\\begin{pmatrix} 3\\\\1 \\end{pmatrix}$\n",
    "\n",
    "* Row space = column space, nullspace ≠ left nullspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 (5 points)\n",
    "\n",
    "(From Strang, section 4.1, problem 18.)\n",
    "\n",
    "Suppose S is spanned by (1,7,3) and (1,1,1).  Then $S^\\perp$ is the nullspace of what matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7 (10 points)\n",
    "\n",
    "If a subspace $S$ is contained in a subspace $V$ ($S \\subseteq V$), then which of the following *must* be true?\n",
    "\n",
    "* $S^\\perp$ contains $V^\\perp$\n",
    "\n",
    "or\n",
    "\n",
    "* $V^\\perp$ contains $S^\\perp$\n",
    "\n",
    "?  Why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
