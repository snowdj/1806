{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 Fall 2018 pset 1\n",
    "\n",
    "## due Wednesday 9/12 at 10:55am by submitting pdf through [Stellar](https://learning-modules.mit.edu/class/index.html?uuid=/course/18/fa18/18.06#info )\n",
    "\n",
    "This problem set is in the form of a [Julia](http://julialang.org/) *notebook* (using the [Jupyter](http://jupyter.org/)/[IJulia](https://github.com/JuliaLang/IJulia.jl) browser-based interface to interactive programming).  We will be using the Julia language throughout the term for simple computational explorations — practical linear algebra is not about hand computations!\n",
    "\n",
    "You can run this without installing anything by logging in at [JuliaBox](https://juliabox.com/).  Just download the notebook file (a `.ipynb` file) by clicking the download icon at the upper right, then drag it onto the JuliaBox dashboard to upload it there. (Although Julia 1.0 was released a few weeks ago, it is not supported yet on JuliaBox, so for now you should *use Julia 0.6*.)\n",
    "\n",
    "Some of the problems are pencil-and-paper (we just happen to use the notebook to describe them), and some of them require you to run the code in the notebook to see what happens and then explain it.  To **run the code** in an input cell, **just click on the cell and then type shift-return**; see also the \"Help\" menu in the notebook.\n",
    "\n",
    "When you submit your pset, you may handwrite or type, but submit **clearly labeled PDFs**.   (An app like Tiny Scanner for your phone makes it easier to scan black-and-white documents into legible PDF files using a cell-phone camera.) For printing a notebook to PDF, you may find that the Jupyter Download-as-PDF or printing *Print Preview* (in the *File* menu at the top of the notebook interface) produces a nicer file than directly printing from your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (10 points)\n",
    "\n",
    "In linear algebra, it is critically important to **think about the shapes** (size) of matrices and vectors, and whether operations make sense.   You can multiply $AB$ if $A$ is $m \\times n$ ($m$ rows and $n$ columns) and $B$ is $n \\times p$ — the \"middle\" dimensions need to match up.  You can also add matrices of *equal* sizes, or multiply them by scalars.  Multiplying $Ax$, an $m \\times n$ matrix $A$ by an $n$-component vector, can be thought of as a special case of this rule if you think of $x$ as an $n \\times 1$ \"matrix\".  On exams, it is common for people to panic and start writing down nonsense, and an easy way to catch this is to make sure that the operations you are writing down **have the correct shapes**.\n",
    "\n",
    "**(a)**\n",
    "\n",
    "If $A$ is a $3\\times 4$ matrix, $B$ is $4\\times 5$, $x$ is $4 \\times 1$ (a 4-component column vector) and $r$ is $1 \\times 3$ (a 3-component [row vector](https://en.wikipedia.org/wiki/Row_and_column_vectors)), **which of the following make sense** and (for those that make sense) **what is the shape of the result**?\n",
    "\n",
    "1. $A^2 = AA$, $AB$, and/or $BA$?\n",
    "2. $3x + A$ and/or $3x + x$?\n",
    "3. $Ax$, $Bx$, $Ar$, $Br$, $xA$, $xB$, $rA$, and/or $rB$?\n",
    "4. $xx$, $xr$, $rx$\n",
    "\n",
    "**Check your answers** in Julia with some random matrices and vectors.  (Julia should give the expected shape for operations that make sense, or print an error for operations that don't.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(3,4)\n",
    "B = rand(4,5)\n",
    "x = rand(4,1)\n",
    "r = rand(1,3); # semicolon at the end suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that A is a 3×4 [array](https://en.wikipedia.org/wiki/Array_data_structure) whose elements are `Float64` (they [\"have decimals\"](https://en.wikipedia.org/wiki/Floating-point_arithmetic)) and it is a \"2-dimensional\" matrix.\n",
    "\n",
    "Now, try out some of the products above, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*B  # = AB … note that you have to write \"*\" to compute the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that you can insert more input cells as needed by using the *Insert* menu at the top of the notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "Later in the class, we will spend a lot of time on the [transpose Aᵀ](https://en.wikipedia.org/wiki/Transpose) of a matrix A, but for now you can think of it as just *swapping rows and columns*: if A is $m \\times n$, then Aᵀ is $n \\times m$, and if $x$ is an $m$-component column vector (or an $m \\times 1$ matrix then $x^T$ is a $1\\times m$ row vector.\n",
    "\n",
    "So, for the examples above, $A^T$ is $4 \\times 3$, $x^T$ is $1\\times 4$, and $r^T$ is $3\\times 1$.\n",
    "\n",
    "For these matrides, which of the following make sense, and (for those that make sense) what is the shape of the result?\n",
    "\n",
    "1. $A^T A$ and/or $AA^T$\n",
    "2. $x^T x$ and/or $x x^T$\n",
    "\n",
    "**Check your answers** by trying them out in Julia.  For real matrices and vectors, $A^T$ is written `A'` in Julia and $x^T$ is written `x'`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A' # the transpose Aᵀ of our real matrix A, giving a 4×3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that you can insert more input cells as needed by using the *Insert* menu at the top of the notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (10 points)\n",
    "\n",
    "**(a)** Give an exact count (a formula in terms of $m,n,p$) of the number of scalar multiplications required to compute the matrix product $AB$, where $A$ is an $m \\times n$ matrix ($m$ rows and $n$ columns) and $B$ is an $n \\times p$ matrix ($n$ rows and $p$ columns).\n",
    "\n",
    "**(b)** Give an exact count (a formula in terms of $m$) of the number of scalar multiplications required to compute the matrix product $Ax$, where $A$ is an $m \\times m$ matrix and $x$ is an $m$-component vector.   Explain how this is equivalent to your answer from part (a) in the special case …………………?\n",
    "\n",
    "**(c)** Computing $ABx$ can be done by $(AB)x$ (first multiplying $AB$ and then multiplying by $x$) or by $A(Bx)$ (first multiplying $Bx$), because matrix multiplication is [associative](https://en.wikipedia.org/wiki/Associative_property).  If $A$ and $B$ are $1000 \\times 1000$ matrices and $x$ is a 1000-component vector, explain why your answers from (a) and (b) imply that *one* of these ways of computing $ABx$ is *much* faster than the other way.\n",
    "\n",
    "Try it out in Julia with some random matrices and compare the results to your prediction based on (a) and (b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(1000,1000)  # random 1000×1000 matrix (entries in [0,1))\n",
    "B = rand(1000,1000)\n",
    "x = rand(1000);       # random 1000-component vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# technicality: turn off multi-threading to make it a bit\n",
    "# easier to interpret benchmark timings:\n",
    "BLAS.set_num_threads(1)\n",
    "\n",
    "# time each way 3 times, and look at the smallest times to reduce noise\n",
    "println(\"timing (A*B)*x:\")\n",
    "@time (A*B)*x\n",
    "@time (A*B)*x\n",
    "@time (A*B)*x\n",
    "println(\"timing A*(B*x):\")\n",
    "@time A*(B*x)\n",
    "@time A*(B*x)\n",
    "@time A*(B*x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your timing ratios should't exactly match the ratios of your count of multiplications — computers are complicated!  but the expected one should be faster.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 points)\n",
    "\n",
    "(From Strang, section 2.2, problem 14.) Consider Gaussian elimination on the following system of equations:\n",
    "\n",
    "$$\n",
    "2x + 5y + z = 0 \\\\\n",
    "4x + dy + z = 2 \\\\\n",
    "y - z = 3\n",
    "$$\n",
    "\n",
    "(Write your solution in matrix form.)\n",
    "\n",
    "* What number $d$ forces you to do a row exchange during elimination, and what (non-singular) triangular system do you obtain for that $d$?\n",
    "* What value of $d$ would make this system singular (no third pivot, i.e. no way to get a triangular system with 3 nonzero values on the diagonal)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (10 points)\n",
    "\n",
    "(From Strang, section 2.2, problem 11.)\n",
    "\n",
    "A system of linear equations Ax=b cannot have *exactly two* solutions. An easy way to see why: if two vectors x and y≠x are two solutions (i.e. Ax=b and Ay=b), what is another solution? (Hint: x+y is almost right.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (15 points)\n",
    "\n",
    "Suppose we want to solve $Ax=b$ for **more than one right-hand side** $b$.  For example, suppose\n",
    "$$\n",
    "A = \\begin{pmatrix} 1 & 6 & -3 \\\\ -2 & 3 & 4 \\\\ 1 & 0 & -2 \\end{pmatrix}\n",
    "$$\n",
    "and want to solve *both* $Ax_1 = b_1$ and $Ax_2 = b_2$ for the right-hand sides:\n",
    "$$\n",
    "b_1 = \\begin{pmatrix} 7 \\\\ 3 \\\\ 0 \\end{pmatrix} \\; b_2 = \\begin{pmatrix} 0 \\\\ -2 \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**(a)**\n",
    "\n",
    "Show that solving *both* $Ax_1 = b_1$ and $Ax_2 = b_2$ is equivalent to solving $AX = B$ where $X$ is an unknown matrix (of what shape?) and B is a given matrix on the right-hand-side.   Give $B$ explicitly, and relate $X$ to your desired solutions $x_1$ and $x_2$.\n",
    "\n",
    "(Hint: think about the \"matrix × columns\" viewpoint of matrix multiplication.)\n",
    "\n",
    "**(b)**\n",
    "\n",
    "Solve your $AX=B$ equation by forming the augmented matrix $\\begin{pmatrix} A & B\\end{pmatrix}$, reducing it to upper-triangular form (once), and doing backsubstitution (twice) to obtain $X$ and hence $x_1$ and $x_2$.\n",
    "\n",
    "**(c)**\n",
    "\n",
    "You can solve $AX = B$ in Julia by the code `X = A \\ B`.  The matrix $A$ is given below in Julia.   Enter the matrix $B$, compute `X = A \\ B`, and verify that it matches the answer you computed by hand in (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [ 1  6 -3\n",
    "     -2  3  4\n",
    "      1  0 -2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [ ???\n",
    "      ???\n",
    "      ??? ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A \\ B   # solve AX = B for X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
